#__Сравнение Feature Importance в sklearn и R__
#__Описание проекта__
Экспериментальное сравнение методов оценки важности признаков (Feature Importance) в реализациях Random Forest для Python (sklearn) и R (randomForest, ranger). Исследование проводилось на различных сценариях данных.
#__Эксперименты__
#__Сценарии данных__
1. __Исходный датасет__ - базовый случай
2. __Коррелированные признаки__ - добавлены дубликаты признака price
3. __Нерелевантные признаки__ - добавлены случайные признаки разных типов

#__Результаты__
__Ключевые наблюдения__
1. Коррелированные признаки: при добавлении дубликатов важность исходного признака уменьшается
2. Нерелевантные признаки: случайные признаки получают ненулевую важность, причем:
random_uniform, random_normal, random_int имеют большую важность чем random_binary

__Решение проблемы с ranger__
При использовании пакета ranger с опцией importance="impurity_corrected" проблема присвоения высокой важности случайным признакам была решена. Алгоритм корректно идентифицирует нерелевантные столбцы и присваивает им близкую к нулю важность, что делает эту реализацию более надежной для реальных задач.
